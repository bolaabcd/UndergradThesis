\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amscd}
\usepackage{amsfonts}
\usepackage{dsfont}
\usepackage{fancyhdr}
\usepackage{enumerate}
\usepackage{steinmetz}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{hyperref}

\usepackage[table]{xcolor}
\setlength{\arrayrulewidth}{0.1mm}
%\setlength{\tabcolsep}{18pt}
\renewcommand{\arraystretch}{2.5}
\newcolumntype{s}{>{\columncolor[HTML]{AAACED}} p{3cm}}
\newcolumntype{r}{p{3mm}}
\newcolumntype{a}{p{10mm}}
%\arrayrulecolor[HTML]{DB5800}
\newcommand{\qm}[1]{``#1"}


\title{Relations between Causality, Fairness, Privacy, Accuracy, Information Flow and Explainability in Machine Learning\large\\ Type: Scientific\\Advisor: Mário Sérgio Alvim}
\author{Artur Gaspar da Silva}
\date{05/04/2024}


\begin{document}
\maketitle

{\color{orange} Table of contents depois ou antes do abstract?}

{\color{orange} Precisa ter tabela de imagens, tabelas e etc.?}

{\color{orange} OK citar coisas do Arxiv?}

{\color{orange} Repetição de artigos que cobrem mais de duas áreas? Talvez só mencionar que foi usado na subseção anterior?}

{\color{orange} Coloca \qm{Chapter x of \textbackslash cite\{...\}} ou \qm{\textbackslash cite[Chapter~x]\{...\}}?}

\begin{abstract}
    Do que podemos falar aqui?
\end{abstract}

\tableofcontents

\section{Introduction}
%Capítulo introdutório: caracterização do problema, motivação, objetivos, breve descrição da estrutura do trabalho.

Recent resarch\cite{Sok}\cite{Reductions}\cite{Rachel}\cite{Awareness} indicates numerous tensions and synergies between many concepts that surround the Machine Learning literature, including Fairness, Privacy, Accuracy and Explainability. For instance, there is an inherent tradeoff between Fairness and Accuracy such that, depending on the data distribution, it might be impossible to develop a model that achieves acceptable values for both fairness and accuracy, if we consider some reasonable fairness metrics\cite{Carlos}. Also, there has been some work on introducing Causality concepts into the discussion, for instance, to develop better fairness metrics\cite{CausalFair}. It has also been suggested to use naturally-interpretable models (as explanations to more complex models) for auditing systems and checking if they are fair, although this might lead to problems\cite{ExplainAll}. This area of research is especially relevant nowadays, given the importance that Machine Learning and Artificial Intelligence systems have: we now have computational systems that are part of processes of making decisions with big impacts on people's lives, for instance, recidivism prediction\cite{Compass}, loan approvals\cite{Loans}, hiring decisions\cite{Jobs}, and others.

In this first part of the Undergraduate Thesis, we provide a concise review of the literature on the topics presented. The main goal is to provide a solid basis for future work on these topics and identify the known connections among them. Section \ref{sec:theoRef1} discusses the already developed theoretical work on these areas, section \ref{sec:theoRef2} discusses connections between them found in the literature, section \ref{sec:contribs} provides the contributions of this analysis in the form of a higher-level discussion of what we can gather from the literature and the meaning of these results, and section \ref{sec:concsFuture} provides conclusions and possible future lines of work. 

\section{Theoretical Background for Individual Concepts}\label{sec:theoRef1}
%Capítulo referencial: identificação de trabalhos correlatos, referencial teórico.

First, we provide a general background on some introductory concepts in the areas of Machine Learning, Causality, Fairness, Privacy, Explainability in Machine Learning, and also Quantitative Information Flow (QIF).

\input{intros}

\section{Contributions: A Review of the Relations Between the Concepts}\label{sec:theoRef2}

In this section we mention comparisons found in the literature between these areas of research, and comment some ideas for unexplored relations in the literature.

\input{pairs}

\section{Conclusions and future work}\label{sec:concsFuture}
%Capítulo de fechamento: conclusões e relação de trabalhos futuros.

We can summarize our findings in the following way:

\begin{enumerate}
    \item \textbf{Accuracy $\times$ Fairness:} There is an inherent trade-off between accuracy and some notions of fairness such as Equal Opportunity Difference and Statistical Parity.
    \item \textbf{Accuracy $\times$ Privacy:} Privacy by addition of noise usually reduces accuracy. Privacy by homomorphic encryption does \emph{not} affect accuracy at the cost of greater computational complexity.
    \item \textbf{Accuracy $\times$ Explainability:} In many situations, more interpretability implies less accuracy (as more compex models are harder to explain/interpret).
    \item \textbf{Accuracy $\times$ Causality:} Causality might help in the transference of machine learning model results between distinct populations, and the development with causal basis can reduce how sensible it is to small changes in the data used to train the model.
    \item \textbf{Accuracy $\times$ QIF:} accuracy can be seem as a form of utility, which usually has a trade-off with information leakage, measured by QIF.
    \item \textbf{Fairness $\times$ Privacy:} If the privacy-preserving mechanism is based on noise, then it might help in reducing unfairness according to some measures. Most results use the noisy distribution directly, without first trying to recover the original distribution.
    \item \textbf{Fairness $\times$ Explainability:} One possibility for checking wheter a system is fair is to demand explanations for the system's working, but sometimes it is possible to deceive this verification.
    \item \textbf{Fairness $\times$ Causality:} there are are many distinct causal fairness notions, each with their own meaning and class of applicable situations.
    \item \textbf{Fairness $\times$ QIF:} Fairness might be measured by \emph{reverse} information flow, how much one can infer from the output by observing the sensitive values of the input instead of how much can be inferred from the input from observing the output.
    \item \textbf{Privacy $\times$ Explainability:} Conceptually, more privacy implies less explaination power as the data points can not be used in explanations. In practice, however, privacy constraints do not seem to have an impact on some of the classical XAI methods.
    \item \textbf{Privacy $\times$ Causality:} Causal interpretations were used to disentangle confusions about Differential Privacy assumptions, we can use causal notions to improve the use of differential privacy budget and some methods make causal discovery/inference harder.
    \item \textbf{Privacy $\times$ QIF:} It is possible to use the Quantitative Information Flow $g$-vulnerability framework to model private information leakage, and there are theoretical results that show relations with differential privacy, with equality for max-vulnerability.
    \item \textbf{Explainability $\times$ Causality:} In many situations, causal explanations the final goal and although classical explainability methods are based only on the data, it might be possible to use them as basis for further empirical explanation.
    \item \textbf{Explainability $\times$ QIF:} The relationship between these two is largely unexplored. Maybe it's possible to provide explanations based on how much information flows from each feature to the output?
    \item \textbf{Causality $\times$ QIF:} The releationship between these two ins largely unexplored too. There is some preliminary unpublished work relating QIF and causal discovery, though. {\color{orange} Faz sentido falar isso?}
\end{enumerate}

{\color{red} Pra future work, talvez QIF pra explicar coisas ou pra fazer ataques contra modelos afinal eu ganho algo e perco algo dependendo do que acontece; Priv vs Fair vs Acc tentando recuperar a distribuição original ao invés de só treinar na obfuscada mesmo sem ligar. Não confio em QIF pra causalidade não, no máximo pega correlações ao ver qual variável é melhor observar pra aumentar o ganho esperado ou algo assim.}

\bibliographystyle{splncs04}
\bibliography{poc1}

% As referências bibliográficas devem ser compostas considerando uma combinação de fontes, entre livros, artigos em periódicos, artigos em anais e fontes eletrônicas, de acordo com as características e a área temática do trabalho. Deve-se procurar ter uma boa diversidade de fontes, que sejam tão atuais quanto possível. Fontes eletrônicas devem ser usadas com critério, já que algumas delas não têm mérito ou qualidade acadêmica. A Internet é uma boa fonte de artigos em meio digital, tanto através de fontes tradicionais como a ACM e a IEEE (acessíveis através do Portal de Periódicos da CAPES), quanto de mecanismos especializados de busca, como o Google Scholar.

\end{document}
