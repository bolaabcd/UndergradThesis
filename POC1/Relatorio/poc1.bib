@article{ateniese2015hacking,
  title={Hacking smart machines with smarter ones: How to extract meaningful data from machine learning classifiers},
  author={Ateniese, Giuseppe and Mancini, Luigi V and Spognardi, Angelo and Villani, Antonio and Vitali, Domenico and Felici, Giovanni},
  journal={International Journal of Security and Networks},
  volume={10},
  number={3},
  pages={137--150},
  year={2015},
  publisher={Inderscience Publishers (IEL)}
}

@inproceedings{fredrikson2015model,
  title={Model inversion attacks that exploit confidence information and basic countermeasures},
  author={Fredrikson, Matt and Jha, Somesh and Ristenpart, Thomas},
  booktitle={Proceedings of the 22nd ACM SIGSAC conference on computer and communications security},
  pages={1322--1333},
  year={2015}
}

@inproceedings{wang2018stealing,
  title={Stealing hyperparameters in machine learning},
  author={Wang, Binghui and Gong, Neil Zhenqiang},
  booktitle={2018 IEEE symposium on security and privacy (SP)},
  pages={36--52},
  year={2018},
  organization={IEEE}
}

@inproceedings{tramer2016stealing,
  title={Stealing machine learning models via prediction $\{$APIs$\}$},
  author={Tram{\`e}r, Florian and Zhang, Fan and Juels, Ari and Reiter, Michael K and Ristenpart, Thomas},
  booktitle={25th USENIX security symposium (USENIX Security 16)},
  pages={601--618},
  year={2016}
}

@inproceedings{bell2023possibility,
  title={The possibility of fairness: Revisiting the impossibility theorem in practice},
  author={Bell, Andrew and Bynum, Lucius and Drushchak, Nazarii and Zakharchenko, Tetiana and Rosenblatt, Lucas and Stoyanovich, Julia},
  booktitle={Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
  pages={400--422},
  year={2023}
}

@article{hsu2022pushing,
  title={Pushing the limits of fairness impossibility: Who's the fairest of them all?},
  author={Hsu, Brian and Mazumder, Rahul and Nandy, Preetam and Basu, Kinjal},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={32749--32761},
  year={2022}
}

@article{hellman2020measuring,
  title={Measuring algorithmic fairness},
  author={Hellman, Deborah},
  journal={Virginia Law Review},
  volume={106},
  number={4},
  pages={811--866},
  year={2020},
  publisher={JSTOR}
}

@book{grohs2022mathematical,
  title={Mathematical aspects of deep learning},
  author={Grohs, Philipp and Kutyniok, Gitta},
  year={2022},
  publisher={Cambridge University Press}
}

@book{calin2020deep,
  title={Deep learning architectures},
  author={Calin, Ovidiu},
  year={2020},
  publisher={Springer}
}

@article{carloni2023role,
  title={The role of causality in explainable artificial intelligence},
  author={Carloni, Gianluca and Berti, Andrea and Colantonio, Sara},
  journal={arXiv preprint arXiv:2309.09901},
  year={2023}
}

@article{ma2023xinsight,
  title={Xinsight: explainable data analysis through the lens of causality},
  author={Ma, Pingchuan and Ding, Rui and Wang, Shuai and Han, Shi and Zhang, Dongmei},
  journal={Proceedings of the ACM on Management of Data},
  volume={1},
  number={2},
  pages={1--27},
  year={2023},
  publisher={ACM New York, NY, USA}
}

@article{vowels2022trying,
  title={Trying to outrun causality with machine learning: Limitations of model explainability techniques for identifying predictive variables},
  author={Vowels, Matthew J},
  journal={stat},
  volume={1050},
  pages={22},
  year={2022}
}

@article{fernandes2022explaining,
  title={Explaining epsilon in local differential privacy through the lens of quantitative information flow},
  author={Fernandes, Natasha and McIver, Annabelle and Sadeghi, Parastoo},
  journal={arXiv preprint arXiv:2210.12916},
  year={2022}
}

@article{alvim2015information,
  title={On the information leakage of differentially-private mechanisms},
  author={Alvim, M{\'a}rio S and Andr{\'e}s, Miguel E and Chatzikokolakis, Konstantinos and Degano, Pierpaolo and Palamidessi, Catuscia},
  journal={Journal of Computer Security},
  volume={23},
  number={4},
  pages={427--469},
  year={2015},
  publisher={IOS Press}
}

@inproceedings{kusner2016private,
  title={Private causal inference},
  author={Kusner, Matt J and Sun, Yu and Sridharan, Karthik and Weinberger, Kilian Q},
  booktitle={Artificial Intelligence and Statistics},
  pages={1308--1317},
  year={2016},
  organization={PMLR}
}

@inproceedings{xu2017differential,
  title={Differential privacy preserving causal graph discovery},
  author={Xu, Depeng and Yuan, Shuhan and Wu, Xintao},
  booktitle={2017 IEEE Symposium on Privacy-Aware Computing (PAC)},
  pages={60--71},
  year={2017},
  organization={IEEE}
}

@inproceedings{tschantz2020sok,
  title={SoK: Differential privacy as a causal property},
  author={Tschantz, Michael Carl and Sen, Shayak and Datta, Anupam},
  booktitle={2020 IEEE Symposium on Security and Privacy (SP)},
  pages={354--371},
  year={2020},
  organization={IEEE}
}

@inproceedings{tople2020alleviating,
  title={Alleviating privacy attacks via causal learning},
  author={Tople, Shruti and Sharma, Amit and Nori, Aditya},
  booktitle={International Conference on Machine Learning},
  pages={9537--9547},
  year={2020},
  organization={PMLR}
}

@article{franco2021toward,
  title={Toward learning trustworthily from data combining privacy, fairness, and explainability: an application to face recognition},
  author={Franco, Danilo and Oneto, Luca and Navarin, Nicol{\`o} and Anguita, Davide},
  journal={Entropy},
  volume={23},
  number={8},
  pages={1047},
  year={2021},
  publisher={MDPI}
}

@inproceedings{binkyte2024causal,
  title={Causal Discovery Under Local Privacy},
  author={Binkyte, Ruta and Pinz{\'o}n, Carlos Antonio and Lesty{\'a}n, Szilvia and Jung, Kangsoo and Arcolezi, H{\'e}ber Hwang and Palamidessi, Catuscia},
  booktitle={Causal Learning and Reasoning},
  pages={325--383},
  year={2024},
  organization={PMLR}
}

@article{grant2020show,
  title={Show us the data: Privacy, explainability, and why the law can't have both},
  author={Grant, Thomas D and Wischik, Damon J},
  journal={Geo. Wash. L. Rev.},
  volume={88},
  pages={1350},
  year={2020},
  publisher={HeinOnline}
}

@article{bozorgpanah2022privacy,
  title={Privacy and explainability: The effects of data protection on Shapley values},
  author={Bozorgpanah, Aso and Torra, Vicen{\c{c}} and Aliahmadipour, Laya},
  journal={Technologies},
  volume={10},
  number={6},
  pages={125},
  year={2022},
  publisher={MDPI}
}

@article{nogueira2023relation,
  title={On the relation of privacy and fairness through the lenses of quantitative information flow},
  author={Nogueira, Bruno Demattos and others},
  year={2023},
  publisher={Universidade Federal de Minas Gerais}
}

@inproceedings{makhlouf2022identifiability,
  title={Identifiability of causal-based ml fairness notions},
  author={Makhlouf, Karima and Zhioua, Sami and Palamidessi, Catuscia},
  booktitle={2022 14th international conference on computational intelligence and communication networks (CICN)},
  pages={1--8},
  year={2022},
  organization={IEEE}
}

@article{saravanakumar2020impossibility,
  title={The Impossibility Theorem of Machine Fairness--A Causal Perspective},
  author={Saravanakumar, Kailash Karthik},
  journal={arXiv preprint arXiv:2007.06024},
  year={2020}
}

@article{su2022review,
  title={A review of causality-based fairness machine learning},
  author={Su, Cong and Yu, Guoxian and Wang, Jun and Yan, Zhongmin and Cui, Lizhen},
  journal={Intelligence \& Robotics},
  volume={2},
  number={3},
  pages={244--274},
  year={2022}
}

@article{makhlouf2024causality,
  title={When Causality Meets Fairness: A Survey},
  author={Makhlouf, Karima and Zhioua, Sami and Palamidessi, Catuscia},
  journal={Journal of Logical and Algebraic Methods in Programming},
  pages={101000},
  year={2024},
  publisher={Elsevier}
}

@article{rueda2022just,
  title={“Just” accuracy? Procedural fairness demands explainability in AI-based medical resource allocations},
  author={Rueda, Jon and Rodr{\'\i}guez, Janet Delgado and Jounou, Iris Parra and Hortal-Carmona, Joaqu{\'\i}n and Aus{\'\i}n, Txetxu and Rodr{\'\i}guez-Arias, David},
  journal={AI \& society},
  pages={1--12},
  year={2022},
  publisher={Springer}
}

@inproceedings{zemel2013learning,
  title={Learning fair representations},
  author={Zemel, Rich and Wu, Yu and Swersky, Kevin and Pitassi, Toni and Dwork, Cynthia},
  booktitle={International conference on machine learning},
  pages={325--333},
  year={2013},
  organization={PMLR}
}

@phdthesis{henao2023exploring,
  title={Exploring fairness and privacy in machine learning},
  author={Henao, Carlos Pinz{\'o}n},
  year={2023},
  school={Institut Polytechnique de Paris}
}

@inproceedings{arcolezi2023local,
  title={(Local) Differential Privacy has NO Disparate Impact on Fairness},
  author={Arcolezi, H{\'e}ber H and Makhlouf, Karima and Palamidessi, Catuscia},
  booktitle={IFIP Annual Conference on Data and Applications Security and Privacy},
  pages={3--21},
  year={2023},
  organization={Springer}
}

@article{makhlouf2024impact,
  title={On the impact of multi-dimensional local differential privacy on fairness},
  author={Makhlouf, Karima and Arcolezi, H{\'e}ber H and Zhioua, Sami and Brahim, Ghassen Ben and Palamidessi, Catuscia},
  journal={Data Mining and Knowledge Discovery},
  pages={1--24},
  year={2024},
  publisher={Springer}
}

@article{zeng2021improving,
  title={Improving the accuracy of network intrusion detection with causal machine learning},
  author={Zeng, Zengri and Peng, Wei and Zhao, Baokang},
  journal={Security and Communication Networks},
  volume={2021},
  number={1},
  pages={8986243},
  year={2021},
  publisher={Wiley Online Library}
}

@incollection{scholkopf2022causality,
  title={Causality for machine learning},
  author={Sch{\"o}lkopf, Bernhard},
  booktitle={Probabilistic and causal inference: The works of Judea Pearl},
  pages={765--804},
  year={2022}
}

@article{richens2020improving,
  title={Improving the accuracy of medical diagnosis with causal machine learning},
  author={Richens, Jonathan G and Lee, Ciar{\'a}n M and Johri, Saurabh},
  journal={Nature communications},
  volume={11},
  number={1},
  pages={3923},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@article{burkart2021survey,
  title={A survey on the explainability of supervised machine learning},
  author={Burkart, Nadia and Huber, Marco F},
  journal={Journal of Artificial Intelligence Research},
  volume={70},
  pages={245--317},
  year={2021}
}

@article{van2021trading,
  title={Trading off accuracy and explainability in AI decision-making: findings from 2 citizens’ juries},
  author={van der Veer, Sabine N and Riste, Lisa and Cheraghi-Sohi, Sudeh and Phipps, Denham L and Tully, Mary P and Bozentko, Kyle and Atwood, Sarah and Hubbard, Alex and Wiper, Carl and Oswald, Malcolm and others},
  journal={Journal of the American Medical Informatics Association},
  volume={28},
  number={10},
  pages={2128--2138},
  year={2021},
  publisher={Oxford University Press}
}

@inproceedings{alufaisan2021does,
  title={Does explainable artificial intelligence improve human decision-making?},
  author={Alufaisan, Yasmeen and Marusich, Laura R and Bakdash, Jonathan Z and Zhou, Yan and Kantarcioglu, Murat},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={8},
  pages={6618--6626},
  year={2021}
}

@inproceedings{bell2022s,
  title={It’s just not that simple: an empirical study of the accuracy-explainability trade-off in machine learning for public policy},
  author={Bell, Andrew and Solano-Kamaiko, Ian and Nov, Oded and Stoyanovich, Julia},
  booktitle={Proceedings of the 2022 ACM conference on fairness, accountability, and transparency},
  pages={248--266},
  year={2022}
}

@article{angelov2021explainable,
  title={Explainable artificial intelligence: an analytical review},
  author={Angelov, Plamen P and Soares, Eduardo A and Jiang, Richard and Arnold, Nicholas I and Atkinson, Peter M},
  journal={Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
  volume={11},
  number={5},
  pages={e1424},
  year={2021},
  publisher={Wiley Online Library}
}

@article{london2019artificial,
  title={Artificial intelligence and black-box medical decisions: accuracy versus explainability},
  author={London, Alex John},
  journal={Hastings Center Report},
  volume={49},
  number={1},
  pages={15--21},
  year={2019},
  publisher={Wiley Online Library}
}

@article{petkovic2023not,
  title={It is not “Accuracy vs. Explainability”—we need both for trustworthy AI systems},
  author={Petkovic, Dragutin},
  journal={IEEE Transactions on Technology and Society},
  volume={4},
  number={1},
  pages={46--53},
  year={2023},
  publisher={IEEE}
}

@inproceedings{liu2016dependence,
  title={Dependence makes you vulnberable: Differential privacy under dependent tuples.},
  author={Liu, Changchang and Chakraborty, Supriyo and Mittal, Prateek},
  booktitle={NDSS},
  volume={16},
  pages={21--24},
  year={2016}
}

@article{ren2018textsf,
  title={LoPub: high-dimensional crowdsourced data publication with local differential privacy},
  author={Ren, Xuebin and Yu, Chia-Mu and Yu, Weiren and Yang, Shusen and Yang, Xinyu and McCann, Julie A and Philip, S Yu},
  journal={IEEE Transactions on Information Forensics and Security},
  volume={13},
  number={9},
  pages={2151--2166},
  year={2018},
  publisher={IEEE}
}

@article{zheng2020preserving,
  title={Preserving user privacy for machine learning: Local differential privacy or federated machine learning?},
  author={Zheng, Huadi and Hu, Haibo and Han, Ziyang},
  journal={IEEE Intelligent Systems},
  volume={35},
  number={4},
  pages={5--14},
  year={2020},
  publisher={IEEE}
}

@article{yang2023local,
  title={Local differential privacy and its applications: A comprehensive survey},
  author={Yang, Mengmeng and Guo, Taolin and Zhu, Tianqing and Tjuawinata, Ivan and Zhao, Jun and Lam, Kwok-Yan},
  journal={Computer Standards \& Interfaces},
  pages={103827},
  year={2023},
  publisher={Elsevier}
}

@inproceedings{yang2005privacy,
  title={Privacy-preserving classification of customer data without loss of accuracy},
  author={Yang, Zhiqiang and Zhong, Sheng and Wright, Rebecca N},
  booktitle={Proceedings of the 2005 SIAM International Conference on Data Mining},
  pages={92--102},
  year={2005},
  organization={SIAM}
}

@inproceedings{friedler2019comparative,
  title={A comparative study of fairness-enhancing interventions in machine learning},
  author={Friedler, Sorelle A and Scheidegger, Carlos and Venkatasubramanian, Suresh and Choudhary, Sonam and Hamilton, Evan P and Roth, Derek},
  booktitle={Proceedings of the conference on fairness, accountability, and transparency},
  pages={329--338},
  year={2019}
}

@article{valdivia2021fair,
  title={How fair can we go in machine learning? Assessing the boundaries of accuracy and fairness},
  author={Valdivia, Ana and S{\'a}nchez-Monedero, Javier and Casillas, Jorge},
  journal={International Journal of Intelligent Systems},
  volume={36},
  number={4},
  pages={1619--1643},
  year={2021},
  publisher={Wiley Online Library}
}

@inproceedings{konstantinov2022impossibility,
  title={On the impossibility of fairness-aware learning from corrupted data},
  author={Konstantinov, Nikola and Lampert, Christoph H},
  booktitle={Algorithmic Fairness through the Lens of Causality and Robustness workshop},
  pages={59--83},
  year={2022},
  organization={PMLR}
}

@article{merono2017cedar,
  title={CEDAR: the Dutch historical censuses as linked open data},
  author={Mero{\~n}o-Pe{\~n}uela, Albert and Ashkpour, Ashkan and Gu{\'e}ret, Christophe and Schlobach, Stefan},
  journal={Semantic Web},
  volume={8},
  number={2},
  pages={297--310},
  year={2017},
  publisher={IOS Press}
}

@article{burkart2021survey,
  title={A survey on the explainability of supervised machine learning},
  author={Burkart, Nadia and Huber, Marco F},
  journal={Journal of Artificial Intelligence Research},
  volume={70},
  pages={245--317},
  year={2021}
}

@article{krishnan2020against,
  title={Against interpretability: a critical examination of the interpretability problem in machine learning},
  author={Krishnan, Maya},
  journal={Philosophy \& Technology},
  volume={33},
  number={3},
  pages={487--502},
  year={2020},
  publisher={Springer}
}

@article{lipton2018mythos,
  title={The mythos of model interpretability: In machine learning, the concept of interpretability is both important and slippery.},
  author={Lipton, Zachary C},
  journal={Queue},
  volume={16},
  number={3},
  pages={31--57},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@misc{makhlouf2024systematicformalstudyimpact,
      title={A Systematic and Formal Study of the Impact of Local Differential Privacy on Fairness: Preliminary Results}, 
      author={Karima Makhlouf and Tamara Stefanovic and Heber H. Arcolezi and Catuscia Palamidessi},
      year={2024},
      eprint={2405.14725},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.14725}, 
}

@article{verma2020counterfactual,
  title={Counterfactual explanations for machine learning: A review},
  author={Verma, Sahil and Dickerson, John and Hines, Keegan},
  journal={arXiv preprint arXiv:2010.10596},
  volume={2},
  pages={1},
  year={2020}
}

@article{carvalho2019machine,
  title={Machine learning interpretability: A survey on methods and metrics},
  author={Carvalho, Diogo V and Pereira, Eduardo M and Cardoso, Jaime S},
  journal={Electronics},
  volume={8},
  number={8},
  pages={832},
  year={2019},
  publisher={MDPI}
}

@article{belle2021principles,
  title={Principles and practice of explainable machine learning},
  author={Belle, Vaishak and Papantonis, Ioannis},
  journal={Frontiers in big Data},
  volume={4},
  pages={688969},
  year={2021},
  publisher={Frontiers Media SA}
}

@article{roscher2020explainable,
  title={Explainable machine learning for scientific insights and discoveries},
  author={Roscher, Ribana and Bohn, Bastian and Duarte, Marco F and Garcke, Jochen},
  journal={Ieee Access},
  volume={8},
  pages={42200--42216},
  year={2020},
  publisher={IEEE}
}

@article{chouldechova2018frontiers,
  title={The frontiers of fairness in machine learning},
  author={Chouldechova, Alexandra and Roth, Aaron},
  journal={arXiv preprint arXiv:1810.08810},
  year={2018}
}

@book{SAAMAP,
  title={Deep learning architectures},
  author={Calin, Ovidiu},
  year={2020},
  publisher={Springer}
}

@article{Vapnik,
  title={An overview of statistical learning theory},
  author={Vapnik, Vladimir N},
  journal={IEEE transactions on neural networks},
  volume={10},
  number={5},
  pages={988--999},
  year={1999},
  publisher={IEEE}
}



@article{Sok,
  title={SoK: Taming the Triangle - On the Interplays between Fairness, Interpretability and Privacy in Machine Learning},
  author={Julien Ferry and Ulrich A{\"i}vodji and S{\'e}bastien Gambs and Marie-Jos{\'e} Huguet and Mohamed Siala},
  journal={ArXiv},
  year={2023},
  volume={abs/2312.16191},
  url={https://api.semanticscholar.org/CorpusID:266573131}
}

@inproceedings{Awareness,
  author = {Dwork, Cynthia and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Zemel, Richard},
  title = {Fairness through awareness},
  year = {2012},
  isbn = {9781450311151},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/2090236.2090255},
  doi = {10.1145/2090236.2090255},
  abstract = {We study fairness in classification, where individuals are classified, e.g., admitted to a university, and the goal is to prevent discrimination against individuals based on their membership in some group, while maintaining utility for the classifier (the university). The main conceptual contribution of this paper is a framework for fair classification comprising (1) a (hypothetical) task-specific metric for determining the degree to which individuals are similar with respect to the classification task at hand; (2) an algorithm for maximizing utility subject to the fairness constraint, that similar individuals are treated similarly. We also present an adaptation of our approach to achieve the complementary goal of "fair affirmative action," which guarantees statistical parity (i.e., the demographics of the set of individuals receiving any classification are the same as the demographics of the underlying population), while treating similar individuals as similarly as possible. Finally, we discuss the relationship of fairness to privacy: when fairness implies privacy, and how tools developed in the context of differential privacy may be applied to fairness.},
  booktitle = {Proceedings of the 3rd Innovations in Theoretical Computer Science Conference},
  pages = {214–226},
  numpages = {13},
  location = {Cambridge, Massachusetts},
  series = {ITCS '12}
}

@article{Impossibility,
  author = {Friedler, Sorelle A. and Scheidegger, Carlos and Venkatasubramanian, Suresh},
  title = {The (Im)possibility of fairness: different value systems require different mechanisms for fair decision making},
  year = {2021},
  issue_date = {April 2021},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {64},
  number = {4},
  issn = {0001-0782},
  url = {https://doi.org/10.1145/3433949},
  doi = {10.1145/3433949},
  abstract = {What does it mean to be fair?},
  journal = {Commun. ACM},
  month = {mar},
  pages = {136–143},
  numpages = {8}
}


@article{FairTensions,
title = {Survey on fairness notions and related tensions},
journal = {EURO Journal on Decision Processes},
volume = {11},
pages = {100033},
year = {2023},
issn = {2193-9438},
doi = {https://doi.org/10.1016/j.ejdp.2023.100033},
url = {https://www.sciencedirect.com/science/article/pii/S2193943823000067},
author = {Guilherme Alves and Fabien Bernier and Miguel Couceiro and Karima Makhlouf and Catuscia Palamidessi and Sami Zhioua},
keywords = {Fairness notion, Tension within fairness, Unfairness mitigation},
abstract = {Automated decision systems are increasingly used to take consequential decisions in problems such as job hiring and loan granting with the hope of replacing subjective human decisions with objective machine learning (ML) algorithms. However, ML-based decision systems are prone to bias, which results in yet unfair decisions. Several notions of fairness have been defined in the literature to capture the different subtleties of this ethical and social concept (e.g., statistical parity, equal opportunity, etc.). Fairness requirements to be satisfied while learning models created several types of tensions among the different notions of fairness and other desirable properties such as privacy and classification accuracy. This paper surveys the commonly used fairness notions and discusses the tensions among them with privacy and accuracy. Different methods to address the fairness-accuracy trade-off (classified into four approaches, namely, pre-processing, in-processing, post-processing, and hybrid) are reviewed. The survey is consolidated with experimental analysis carried out on fairness benchmark datasets to illustrate the relationship between fairness measures and accuracy in real-world scenarios.}
}

@inproceedings{Rachel,
author = {Cummings, Rachel and Gupta, Varun and Kimpara, Dhamma and Morgenstern, Jamie},
title = {On the Compatibility of Privacy and Fairness},
year = {2019},
isbn = {9781450367110},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3314183.3323847},
doi = {10.1145/3314183.3323847},
abstract = {In this work, we investigate whether privacy and fairness can be simultaneously achieved by a single classifier in several different models. Some of the earliest work on fairness in algorithm design defined fairness as a guarantee of similar outputs for "similar'' input data, a notion with tight technical connections to differential privacy. We study whether tensions exist between differential privacy and statistical notions of fairness, namely Equality of False Positives and Equality of False Negatives (EFP/EFN). We show that even under full distributional access, there are cases where the constraint of differential privacy precludes exact EFP/EFN. We then turn to ask whether one can learn a differentially private classifier which approximately satisfies EFP/EFN, and show the existence of a PAC learner which is private and approximately fair with high probability. We conclude by giving an efficient algorithm for classification that maintains utility and satisfies both privacy and approximate fairness with high probability.},
booktitle = {Adjunct Publication of the 27th Conference on User Modeling, Adaptation and Personalization},
pages = {309–315},
numpages = {7},
keywords = {differential privacy, fairness, learning theory},
location = {Larnaca, Cyprus},
series = {UMAP'19 Adjunct}
}

@Article{Carlos,
author={Pinz{\'o}n, Carlos
and Palamidessi, Catuscia
and Piantanida, Pablo
and Valencia, Frank},
title={On the incompatibility of accuracy and equal opportunity},
journal={Machine Learning},
year={2023},
month={May},
day={02},
abstract={One of the main concerns about fairness in machine learning (ML) is that, in order to achieve it, one may have to trade off some accuracy. To overcome this issue, Hardt et al. (Adv Neural Inf Process Syst 29, 2016) proposed the notion of equality of opportunity (EO), which is compatible with maximal accuracy when the target label is deterministic with respect to the input features. In the probabilistic case, however, the issue is more complicated: It has been shown that under differential privacy constraints, there are data sources for which EO can only be achieved at the total detriment of accuracy, in the sense that a classifier that satisfies EO cannot be more accurate than a trivial (i.e., constant) classifier. In this paper, we strengthen this result by removing the privacy constraint. Namely, we show that for certain data sources, the most accurate classifier that satisfies EO is a trivial classifier. Furthermore, we study the admissible trade-offs between accuracy and EO loss (opportunity difference) and characterize the conditions on the data source under which EO and non-trivial accuracy are compatible.},
issn={1573-0565},
doi={10.1007/s10994-023-06331-y},
url={https://doi.org/10.1007/s10994-023-06331-y}
}


@InProceedings{Reductions,
  title = 	 {A Reductions Approach to Fair Classification},
  author =       {Agarwal, Alekh and Beygelzimer, Alina and Dudik, Miroslav and Langford, John and Wallach, Hanna},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {60--69},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/agarwal18a/agarwal18a.pdf},
  url = 	 {https://proceedings.mlr.press/v80/agarwal18a.html},
  abstract = 	 {We present a systematic approach for achieving fairness in a binary classification setting. While we focus on two well-known quantitative definitions of fairness, our approach encompasses many other previously studied definitions as special cases. The key idea is to reduce fair classification to a sequence of cost-sensitive classification problems, whose solutions yield a randomized classifier with the lowest (empirical) error subject to the desired constraints. We introduce two reductions that work for any representation of the cost-sensitive classifier and compare favorably to prior baselines on a variety of data sets, while overcoming several of their disadvantages.}
}


@article{CausalFair,
  title={Survey on Causal-based Machine Learning Fairness Notions}, 
  author={Karima Makhlouf and Sami Zhioua and Catuscia Palamidessi},
  year={2022},
  eprint={2010.09553},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}


@inproceedings{Bruno,
title = "On the duality of privacy and fairness (extended abstract)",
abstract = "When a machine learning model operates over data about individuals, there are two common concerns. On one hand, if the model{\textquoteright}s output (i.e., its prediction) allows for information inferences about an individual{\textquoteright}s sensitive attributes, we have a privacy issue. On the other hand, if the individual{\textquoteright}s sensitive attributes can unduly influence the model{\textquoteright}s output, we have a fairness issue. Recently, the interplay between these two concerns has gathered growing attention both in the scientific community and in society as a whole. In this work, we extend the framework of quantitative information flow to formally capture fairness and privacy as duals of each other, and give first steps toward a novel characterization of their relationship.",
author = "Alvim, {M{\'a}rio S.} and Natasha Fernandes and Nogueira, {Bruno D.} and Catuscia Palamidessi and Silva, {Thiago V. A.}",
year = "2023",
doi = "10.1049/icp.2023.2563",
language = "English",
booktitle = "International Conference on AI and the Digital Economy (CADE 2023)",
publisher = "Institution of Engineering and Technology",
address = "United Kingdom",
note = "9th International Conference on AI and the Digital Economy, CADE 2023 ; Conference date: 26-06-2023 Through 28-06-2023",

}

@book{Causality,
author = {Pearl, Judea},
title = {Causality: Models, Reasoning and Inference},
year = {2009},
isbn = {052189560X},
publisher = {Cambridge University Press},
address = {USA},
edition = {2nd},
abstract = {Written by one of the preeminent researchers in the field, this book provides a comprehensive exposition of modern analysis of causation. It shows how causality has grown from a nebulous concept into a mathematical theory with significant applications in the fields of statistics, artificial intelligence, economics, philosophy, cognitive science, and the health and social sciences. Judea Pearl presents and unifies the probabilistic, manipulative, counterfactual, and structural approaches to causation and devises simple mathematical tools for studying the relationships between causal connections and statistical associations. The book will open the way for including causal analysis in the standard curricula of statistics, artificial intelligence, business, epidemiology, social sciences, and economics. Students in these fields will find natural models, simple inferential procedures, and precise mathematical definitions of causal concepts that traditional texts have evaded or made unduly complicated. The first edition of Causality has led to a paradigmatic change in the way that causality is treated in statistics, philosophy, computer science, social science, and economics. Cited in more than 3,000 scientific publications, it continues to liberate scientists from the traditional molds of statistical thinking. In this revised edition, Judea Pearl elucidates thorny issues, answers readers' questions, and offers a panoramic view of recent advances in this field of research. Causality will be of interests to students and professionals in a wide variety of fields. Anyone who wishes to elucidate meaningful relationships from data, predict effects of actions and policies, assess explanations of reported events, or form theories of causal understanding and causal speech will find this book stimulating and invaluable.}
}


@book{CausalInf,
  title={Causal Inference in Statistics: A Primer},
  author={Pearl, J. and Glymour, M. and Jewell, N.P.},
  isbn={9781119186847},
  lccn={2015037219},
  url={https://books.google.com.br/books?id=L3G-CgAAQBAJ},
  year={2016},
  publisher={Wiley}
}


@book{QIF,
  title={The Science of Quantitative Information Flow},
  author={Alvim, M.S. and Chatzikokolakis, K. and McIver, A. and Morgan, C. and Palamidessi, C. and Smith, G.},
  isbn={9783319961316},
  series={Information Security and Cryptography},
  url={https://books.google.com.br/books?id=jJH-DwAAQBAJ},
  year={2020},
  publisher={Springer International Publishing}
}

@book{InfoTheory,
  title={Information Theory , Inference And Learning Algorithms},
  author={MacKay, David JC},
  isbn={9780521670517},
  url={https://books.google.com.br/books?id=4WhiPgAACAAJ},
  year={2005},
  publisher={Cambridge University Press}
}

@inproceedings{ExplainAll,
author = {Zhou, Joyce and Joachims, Thorsten},
title = {How to Explain and Justify Almost Any Decision: Potential Pitfalls for Accountability in AI Decision-Making},
year = {2023},
isbn = {9798400701924},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593013.3593972},
doi = {10.1145/3593013.3593972},
abstract = {Discussion of the “right to an explanation” has been increasingly relevant because of its potential utility for auditing automated decision systems, as well as for making objections to such decisions. However, most existing work on explanations focuses on collaborative environments, where designers are motivated to implement good-faith explanations that reveal potential weaknesses of a decision system. This motivation may not hold in an auditing environment. Thus, we ask: how much could explanations be used maliciously to defend a decision system? In this paper, we demonstrate how a black-box explanation system developed to defend a black-box decision system could manipulate decision recipients or auditors into accepting an intentionally discriminatory decision model. In a case-by-case scenario where decision recipients are unable to share their cases and explanations, we find that most individual decision recipients could receive a verifiable justification, even if the decision system is intentionally discriminatory. In a system-wide scenario where every decision is shared, we find that while justifications frequently contradict each other, there is no intuitive threshold to determine if these contradictions are because of malicious justifications or because of simplicity requirements of these justifications conflicting with model behavior. We end with discussion of how system-wide metrics may be more useful than explanation systems for evaluating overall decision fairness, while explanations could be useful outside of fairness auditing.},
booktitle = {Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
pages = {12–21},
numpages = {10},
keywords = {adversarial explanations, explainable AI, right to an explanation},
location = {, Chicago, IL, USA, },
series = {FAccT '23}
}

@article{Compass,
  title={Machine bias: There’s software used across the country to predict future criminals. and it’s biased against blacks.},
  author={Angwin, Julia and Larson, Jeff and Mattu, Surya and Kirchner, Lauren},
  journal={URL https://www. propublica. org/article/machine-bias-risk-assessments-in-criminal-sentencing},
  year={2019}
}

@inproceedings{Loans,
  title={An approach for prediction of loan approval using machine learning algorithm},
  author={Sheikh, Mohammad Ahmad and Goel, Amit Kumar and Kumar, Tapas},
  booktitle={2020 international conference on electronics and sustainable communication systems (ICESC)},
  pages={490--494},
  year={2020},
  organization={IEEE}
}

@inproceedings{Jobs,
  title={Algorithmic hiring in practice: Recruiter and HR Professional's perspectives on AI use in hiring},
  author={Li, Lan and Lassiter, Tina and Oh, Joohee and Lee, Min Kyung},
  booktitle={Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
  pages={166--176},
  year={2021}
}

@article{FairMeasures,
author = {Makhlouf, Karima and Zhioua, Sami and Palamidessi, Catuscia},
title = {On the Applicability of Machine Learning Fairness Notions},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {1},
issn = {1931-0145},
url = {https://doi.org/10.1145/3468507.3468511},
doi = {10.1145/3468507.3468511},
abstract = {Machine Learning (ML) based predictive systems are increasingly used to support decisions with a critical impact on individuals' lives such as college admission, job hiring, child custody, criminal risk assessment, etc. As a result, fairness emerged as an important requirement to guarantee that ML predictive systems do not discriminate against specific individuals or entire sub-populations, in particular, minorities. Given the inherent subjectivity of viewing the concept of fairness, several notions of fairness have been introduced in the literature. This paper is a survey of fairness notions that, unlike other surveys in the literature, addresses the question of "which notion of fairness is most suited to a given real-world scenario and why?". Our attempt to answer this question consists in (1) identifying the set of fairness-related characteristics of the real-world scenario at hand, (2) analyzing the behavior of each fairness notion, and then (3) fitting these two elements to recommend the most suitable fairness notion in every specific setup. The results are summarized in a decision diagram that can be used by practitioners and policy makers to navigate the relatively large catalogue of ML fairness notions.},
journal = {SIGKDD Explor. Newsl.},
month = {may},
pages = {14–23},
numpages = {10}
}

@inproceedings{FairSolve,
  title={Improving fairness in machine learning systems: What do industry practitioners need?},
  author={Holstein, Kenneth and Wortman Vaughan, Jennifer and Daum{\'e} III, Hal and Dudik, Miro and Wallach, Hanna},
  booktitle={Proceedings of the 2019 CHI conference on human factors in computing systems},
  pages={1--16},
  year={2019}
}


@inproceedings{DP,
  title={Differential privacy},
  author={Dwork, Cynthia},
  booktitle={International colloquium on automata, languages, and programming},
  pages={1--12},
  year={2006},
  organization={Springer}
}

@inproceedings{ExplDev,
  title={Predicting software defects with explainable machine learning},
  author={Santos, Geanderson and Figueiredo, Eduardo and Veloso, Adriano and Viggiato, Markos and Ziviani, Nivio},
  booktitle={Proceedings of the XIX Brazilian Symposium on Software Quality},
  pages={1--10},
  year={2020}
}


@article{ExplainExperts,
  title={Explainable machine learning for scientific insights and discoveries},
  author={Roscher, Ribana and Bohn, Bastian and Duarte, Marco F and Garcke, Jochen},
  journal={Ieee Access},
  volume={8},
  pages={42200--42216},
  year={2020},
  publisher={IEEE}
}

@article{mehrabi2021survey,
  title={A survey on bias and fairness in machine learning},
  author={Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
  journal={ACM computing surveys (CSUR)},
  volume={54},
  number={6},
  pages={1--35},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{alves2023survey,
  title={Survey on fairness notions and related tensions},
  author={Alves, Guilherme and Bernier, Fabien and Couceiro, Miguel and Makhlouf, Karima and Palamidessi, Catuscia and Zhioua, Sami},
  journal={EURO journal on decision processes},
  volume={11},
  pages={100033},
  year={2023},
  publisher={Elsevier}
}

@article{chouldechova2018frontiers,
  title={The frontiers of fairness in machine learning},
  author={Chouldechova, Alexandra and Roth, Aaron},
  journal={arXiv preprint arXiv:1810.08810},
  year={2018}
}

@inproceedings{kearns2018preventing,
  title={Preventing fairness gerrymandering: Auditing and learning for subgroup fairness},
  author={Kearns, Michael and Neel, Seth and Roth, Aaron and Wu, Zhiwei Steven},
  booktitle={International conference on machine learning},
  pages={2564--2572},
  year={2018},
  organization={PMLR}
}

@article{dwork2018fairness,
  title={Fairness under composition},
  author={Dwork, Cynthia and Ilvento, Christina},
  journal={arXiv preprint arXiv:1806.06122},
  year={2018}
}

@article{liu2021machine,
  title={When machine learning meets privacy: A survey and outlook},
  author={Liu, Bo and Ding, Ming and Shaham, Sina and Rahayu, Wenny and Farokhi, Farhad and Lin, Zihuai},
  journal={ACM Computing Surveys (CSUR)},
  volume={54},
  number={2},
  pages={1--36},
  year={2021},
  publisher={ACM New York, NY, USA}
}


@inproceedings{gilpin2018explaining,
  title={Explaining explanations: An overview of interpretability of machine learning},
  author={Gilpin, Leilani H and Bau, David and Yuan, Ben Z and Bajwa, Ayesha and Specter, Michael and Kagal, Lalana},
  booktitle={2018 IEEE 5th International Conference on data science and advanced analytics (DSAA)},
  pages={80--89},
  year={2018},
  organization={IEEE}
}

@article{linardatos2020explainable,
  title={Explainable ai: A review of machine learning interpretability methods},
  author={Linardatos, Pantelis and Papastefanopoulos, Vasilis and Kotsiantis, Sotiris},
  journal={Entropy},
  volume={23},
  number={1},
  pages={18},
  year={2020},
  publisher={MDPI}
}

@inproceedings{ribeiro2016should,
  title={" Why should i trust you?" Explaining the predictions of any classifier},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1135--1144},
  year={2016}
}

@article{lundberg2017unified,
  title={A unified approach to interpreting model predictions},
  author={Lundberg, Scott M and Lee, Su-In},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}


