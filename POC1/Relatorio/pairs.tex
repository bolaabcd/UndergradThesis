\subsection{Accuracy $\times$ Fairness}

There are results that indicate an inherent trade-off between fairness and accuracy in machine learning:

\begin{enumerate}
\item \cite{Carlos} shows that there are trade-offs between Equal Oportunity Difference and accuracy such that, depending on the data distribution, it might impossible to achieve both perfect Equal Oportunity Difference and non-trivial accuracy. It also shows some other theoretical results that associate EOD and accuracy, such as sufficient conditions for the existance of non-trivially accurate predictors that lead to zero Equal Opportunity Difference and non-trivial accuracy and algebraic and geometric properties of the feasible values of Equal Opportunity Difference and accuracy.
\item \cite{Reductions} provides methods for computing the best possible accuracy given some level of fairness, for a general notion of fairness that encompasses many common metrics. They devise an algorithm for solving a constrained linear optimization problem that minimizes the error subject to fairness constraints, and provide experimental results for some datasets, including the COMPAS \cite{Compass} dataset. One interesting results is that for some datasets (such as the Compas dataset), it is possible to reduce Equal Opportunity Difference without changing much the accuracy, but for some datasets (such as the Dutch Census Dataset\cite{Dutch} with gender as the protected attribute and the goal is if someone has a prestigious occupation) {\color{red} Dutch Census deve ser esse: \url{https://www.researchgate.net/profile/Eric-Schulte-Nordholt/publication/286099390_The_Dutch_Census_2011/links/58a3228b458515d15fd942d2/The-Dutch-Census-2011.pdf}}
\item \cite{How fair can we go in machine learning? Assessing the boundaries of accuracy and fairness} Provides a method of finding the full Paretto front of accuracy versus fairness. Their approach is based on a genetic algorithm, and the notion of fairness that they consider is False-Positive Rate for avoiding disparate mistreatment, but it is possible to use most metrics available in the literature.
\item \cite{A comparative study of fairness-enhancing interventions in machine learning} provides empirical analysis of some of the existing fairness-enhancing methods for machine learning, showing that the results are influenced a lot by the fairness notion used and also by the dataset.
\end{enumerate}

\subsection{Accuracy $\times$ Privacy}

{\color{red} Differential privacy literature should have something}

\subsection{Accuracy $\times$ Explainability}

{\color{red} Probably can find it in the explainability literature}

\subsection{Accuracy $\times$ Causality}

{\color{red} Maybe we can say that accuracy lies in the first ladder of causation, and usually we want to answer questions on other levels?}

\subsection{Accuracy $\times$ QIF}

{\color{red} Accuracy can be seen as a form of utility, maybe this is usefull for statistical disclosure control.}

\subsection{Fairness $\times$ Privacy}

{\color{red} Rachel's paper, fairness through awareness maybe, and others. Awareness is about being fair by a generalization of differential privacy if I recall correctly, at least in individual fairness, the relations with group fairness and other stuff.}

\subsection{Fairness $\times$ Explainability}

{\color{red} Some people try to judge fairness based on the explanation, we can mention the How to Justify Almost Anything aqui, que pra auditar pode não ser uma boa ideia, só isso mesmo talvez.}

\subsection{Fairness $\times$ Causality}

{\color{red} Citar paper Karima sobre noções causais de fairness.}

\subsection{Fairness $\times$ QIF}

{\color{red} Citar trabalho do Bruno sobre QIF ao contrário como noção de fairness talvez}

\subsection{Privacy $\times$ Explainability}

{\color{red} No idea!}

\subsection{Privacy $\times$ Causality}

{\color{red} No idea! Maybe be private to causal discovery? Maybe be private but allow causal discovery? I think that there is a paper by Sylvia about this...}

\subsection{Privacy $\times$ QIF}

{\color{red} QIF was desined to work with privacy, quantifying how much the sensitive information is leaking is in a way quantifying privacy.}

\subsection{Explainability $\times$ Causality}

{\color{red} Causality is inheretely easier to explain.}

\subsection{Explainability $\times$ QIF}

{\color{red} No idea! Maybe a way to see which variables leak more information?}

\subsection{Causality $\times$ QIF}

{\color{red} I don't think that the paper I saw was published, but maybe we can mention that.}

